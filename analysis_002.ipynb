{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "python version = 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:12:31) [Clang 14.0.6 ]\n",
      "numpy version = 1.26.4\n",
      "xarray version = 2024.2.0\n",
      "pytorch version = 2.1.2.post2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['PROJ_DATA'] = \"/pscratch/sd/p/plutzner/proj_data\"\n",
    "import xarray as xr\n",
    "import torch\n",
    "import torchinfo\n",
    "import random\n",
    "import numpy as np\n",
    "import importlib as imp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import cartopy.crs as ccrs\n",
    "import json\n",
    "import pickle\n",
    "import gzip\n",
    "#import matplotlib.colors as mcolorsxx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils\n",
    "import utils.filemethods as filemethods\n",
    "import databuilder.data_loader as data_loader\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "from databuilder.data_generator import multi_input_data_organizer\n",
    "import databuilder.data_loader as data_loader\n",
    "from trainer.trainer import Trainer\n",
    "from model.build_model import TorchModel\n",
    "from utils import utils\n",
    "# import databuilder.nino_indices as nino_indices # CAUSES CELL TO HANG\n",
    "\n",
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"xarray version = {xr.__version__}\")\n",
    "print(f\"pytorch version = {torch.__version__}\")\n",
    "\n",
    "# https://github.com/victoresque/pytorch-template/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = utils.get_config(\"exp002\")\n",
    "seed = config[\"seed_list\"][0]\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process + Pickle Inputs and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s_dict_train, s_dict_val, s_dict_test = multi_input_data_organizer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dict_savename1 = '/Users/C830793391/BIG_DATA/E3SM_Data/presaved/Network Inputs/exp002_train.pkl'\n",
    "# with gzip.open(s_dict_savename1, \"wb\") as fp:\n",
    "#     pickle.dump(s_dict_train, fp)\n",
    "\n",
    "s_dict_savename2 = '/Users/C830793391/BIG_DATA/E3SM_Data/presaved/Network Inputs/exp002_val.pkl'\n",
    "# with gzip.open(s_dict_savename2, \"wb\") as fp:\n",
    "#     pickle.dump(s_dict_val, fp)\n",
    "\n",
    "s_dict_savename3 = '/Users/C830793391/BIG_DATA/E3SM_Data/presaved/Network Inputs/exp002_test.pkl'\n",
    "# with gzip.open(s_dict_savename3, \"wb\") as fp:\n",
    "#     pickle.dump(s_dict_test, fp)\n",
    "\n",
    "with gzip.open(s_dict_savename1, \"rb\") as obj1:\n",
    "    train_dat = pickle.load(obj1)\n",
    "obj1.close()\n",
    "\n",
    "with gzip.open(s_dict_savename2, \"rb\") as obj2:\n",
    "    val_dat = pickle.load(obj2)\n",
    "obj2.close()\n",
    "\n",
    "with gzip.open(s_dict_savename3, \"rb\") as obj3:\n",
    "    test_dat = pickle.load(obj3)\n",
    "obj3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(train_dat[\"x\"][135:-32]).any())\n",
    "print(np.isnan(val_dat[\"x\"][135:-32]).any())\n",
    "print(np.isnan(test_dat[\"x\"][135:-32]).any())\n",
    "\n",
    "print(np.isnan(train_dat[\"y\"][135:-32]).any())\n",
    "print(np.isnan(val_dat[\"y\"][135:-32]).any())\n",
    "print(np.isnan(test_dat[\"y\"][135:-32]).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = train_dat[\"x\"][121:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve Data: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 shape: (60058, 3)\n",
      "Target shape: (60058,)\n",
      "X1 shape: (60058, 3)\n",
      "Target shape: (60058,)\n"
     ]
    }
   ],
   "source": [
    "# Setup the Data\n",
    "trainset = data_loader.CustomData(config[\"data_loader\"][\"data_dir\"] + \"/Network Inputs/exp002_train.pkl\")\n",
    "valset = data_loader.CustomData(config[\"data_loader\"][\"data_dir\"] + \"/Network Inputs/exp002_val.pkl\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=config[\"data_loader\"][\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=config[\"data_loader\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Model\n",
    "model = TorchModel(\n",
    "    config=config[\"arch\"],\n",
    "    target_mean=trainset.target.mean(axis=0),\n",
    "    target_std=trainset.target.std(axis=0),\n",
    ")\n",
    "# model.freeze_layers(freeze_id=\"tau\")\n",
    "optimizer = getattr(torch.optim, config[\"optimizer\"][\"type\"])(\n",
    "    model.parameters(), **config[\"optimizer\"][\"args\"]\n",
    ")\n",
    "criterion = getattr(module_loss, config[\"criterion\"])()\n",
    "metric_funcs = [getattr(module_metric, met) for met in config[\"metrics\"]]\n",
    "\n",
    "# Build the trainer\n",
    "device = utils.prepare_device(config[\"device\"])\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    criterion,\n",
    "    metric_funcs,\n",
    "    optimizer,\n",
    "    max_epochs=config[\"trainer\"][\"max_epochs\"],\n",
    "    data_loader=train_loader,\n",
    "    validation_data_loader=val_loader,\n",
    "    device=device,\n",
    "    config=config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "TorchModel                               [64, 3]                   [64, 4]                   20\n",
      "├─Linear: 1-1                            [64, 3]                   [64, 3]                   12\n",
      "├─Linear: 1-2                            [64, 3]                   [64, 3]                   12\n",
      "├─Linear: 1-3                            [64, 3]                   [64, 4]                   16\n",
      "===================================================================================================================\n",
      "Total params: 60\n",
      "Trainable params: 60\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "===================================================================================================================\n",
      "Epoch   0/30\n",
      "  7.7s - train_loss: 4.11965 - val_loss: inf\n",
      "Epoch   1/30\n",
      "  7.7s - train_loss: inf - val_loss: nan\n",
      "Epoch   2/30\n",
      "  8.0s - train_loss: nan - val_loss: nan\n",
      "Epoch   3/30\n",
      "  7.6s - train_loss: nan - val_loss: nan\n",
      "Restoring model weights from the end of the best epoch None: val_loss = inf\n",
      "  epoch = 0.00000 | 1.00000 | 2.00000 | 3.00000 | 4.00000\n",
      "  loss = 4.11965 | inf | nan | nan | nan\n",
      "  val_loss = inf | nan | nan | nan | nan\n",
      "  custom_mae = 9.68404 | 9.40447 | nan | nan | nan\n",
      "  iqr_capture = 0.67899 | 0.14404 | 0.00000 | 0.00000 | 0.00000\n",
      "  sign_test = 0.35551 | 0.08164 | 0.00000 | 0.00000 | 0.00000\n",
      "  val_custom_mae = 9.59157 | nan | nan | nan | nan\n",
      "  val_iqr_capture = 0.68609 | 0.00000 | 0.00000 | 0.00000 | 0.00000\n",
      "  val_sign_test = 0.37895 | 0.00000 | 0.00000 | 0.00000 | 0.00000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class 'NoneType'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the Model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Research/E3SM/base/base_trainer.py:84\u001b[0m, in \u001b[0;36mBaseTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRestoring model weights from the end of the best epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopper\u001b[38;5;241m.\u001b[39mbest_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopper\u001b[38;5;241m.\u001b[39mmin_validation_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mprint(idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopper\u001b[38;5;241m.\u001b[39mbest_epoch)\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_model_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/env-torch/lib/python3.10/site-packages/torch/nn/modules/module.py:2103\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copies parameters and buffers from :attr:`state_dict` into\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;124;03mthis module and its descendants. If :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[1;32m   2071\u001b[0m \u001b[38;5;124;03mthe keys of :attr:`state_dict` must exactly match the keys returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[38;5;124;03m    ``RuntimeError``.\u001b[39;00m\n\u001b[1;32m   2101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state_dict, Mapping):\n\u001b[0;32m-> 2103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected state_dict to be dict-like, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(state_dict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2105\u001b[0m missing_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2106\u001b[0m unexpected_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class 'NoneType'>."
     ]
    }
   ],
   "source": [
    "# Visualize the model\n",
    "torchinfo.summary(\n",
    "    model,\n",
    "    [   trainset.input[: config[\"data_loader\"][\"batch_size\"]].shape ],\n",
    "    verbose=1,\n",
    "    col_names=(\"input_size\", \"output_size\", \"num_params\"),\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "model.to(device)\n",
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
