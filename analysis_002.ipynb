{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "python version = 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]\n",
      "numpy version = 1.26.4\n",
      "xarray version = 2024.5.0\n",
      "pytorch version = 2.0.0.post104\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['PROJ_DATA'] = \"/pscratch/sd/p/plutzner/proj_data\"\n",
    "import xarray as xr\n",
    "import torch\n",
    "import torchinfo\n",
    "import random\n",
    "import numpy as np\n",
    "import importlib as imp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import cartopy.crs as ccrs\n",
    "import json\n",
    "import pickle\n",
    "import gzip\n",
    "#import matplotlib.colors as mcolorsxx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils\n",
    "import utils.filemethods as filemethods\n",
    "import databuilder.data_loader as data_loader\n",
    "from databuilder.data_generator import multi_input_data_organizer\n",
    "import databuilder.data_loader as data_loader\n",
    "from trainer.trainer import Trainer\n",
    "from model.build_model import TorchModel\n",
    "from utils import utils\n",
    "# import databuilder.nino_indices as nino_indices # CAUSES CELL TO HANG\n",
    "\n",
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"xarray version = {xr.__version__}\")\n",
    "print(f\"pytorch version = {torch.__version__}\")\n",
    "\n",
    "# https://github.com/victoresque/pytorch-template/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.get_config(\"exp002\")\n",
    "seed = config[\"seed_list\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process + Pickle Inputs and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening MJO PCs\n",
      "Opening Nino34 Data\n",
      "/pscratch/sd/p/plutzner/E3SM/bigdata/E3SMv2data/member0101/member0101.Nino34.daily.int.nc\n",
      "Opening Target data\n"
     ]
    }
   ],
   "source": [
    "s_dict_train, s_dict_val, s_dict_test = multi_input_data_organizer(config)\n",
    "\n",
    "s_dict_savename1 = '/pscratch/sd/p/plutzner/E3SM/bigdata/presaved/exp002_train.pkl'\n",
    "with gzip.open(s_dict_savename1, \"wb\") as fp:\n",
    "    pickle.dump(s_dict_train, fp)\n",
    "\n",
    "s_dict_savename2 = '/pscratch/sd/p/plutzner/E3SM/bigdata/presaved/exp002_val.pkl'\n",
    "with gzip.open(s_dict_savename2, \"wb\") as fp:\n",
    "    pickle.dump(s_dict_val, fp)\n",
    "\n",
    "s_dict_savename3 = '/pscratch/sd/p/plutzner/E3SM/bigdata/presaved/exp002_test.pkl'\n",
    "with gzip.open(s_dict_savename3, \"wb\") as fp:\n",
    "    pickle.dump(s_dict_test, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve Data: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Data\n",
    "trainset = data_loader.CustomData(config[\"data_loader\"][\"data_dir\"] + \"exp002_train.pkl\")\n",
    "valset = data_loader.CustomData(config[\"data_loader\"][\"data_dir\"] + \"exp002_val.pkl\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=config[\"data_loader\"][\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=config[\"data_loader\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Model\n",
    "model = TorchModel(\n",
    "    config=config[\"arch\"],\n",
    "    target_mean=trainset.target.mean(axis=0),\n",
    "    target_std=trainset.target.std(axis=0),\n",
    ")\n",
    "model.freeze_layers(freeze_id=\"tau\")\n",
    "optimizer = getattr(torch.optim, config[\"optimizer\"][\"type\"])(\n",
    "    model.parameters(), **config[\"optimizer\"][\"args\"]\n",
    ")\n",
    "criterion = getattr(module_loss, config[\"criterion\"])()\n",
    "metric_funcs = [getattr(module_metric, met) for met in config[\"metrics\"]]\n",
    "\n",
    "# Build the trainer\n",
    "device = utils.prepare_device(config[\"device\"])\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    criterion,\n",
    "    metric_funcs,\n",
    "    optimizer,\n",
    "    max_epochs=config[\"trainer\"][\"max_epochs\"],\n",
    "    data_loader=train_loader,\n",
    "    validation_data_loader=val_loader,\n",
    "    device=device,\n",
    "    config=config,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
