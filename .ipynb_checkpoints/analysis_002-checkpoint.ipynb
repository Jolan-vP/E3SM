{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "python version = 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]\n",
      "numpy version = 1.26.4\n",
      "xarray version = 2024.5.0\n",
      "pytorch version = 2.0.0.post104\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['PROJ_DATA'] = \"/pscratch/sd/p/plutzner/proj_data\"\n",
    "import xarray as xr\n",
    "import torch\n",
    "import torchinfo\n",
    "import random\n",
    "import numpy as np\n",
    "import importlib as imp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import cartopy.crs as ccrs\n",
    "import json\n",
    "import pickle\n",
    "import gzip\n",
    "#import matplotlib.colors as mcolorsxx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils\n",
    "import utils.filemethods as filemethods\n",
    "import databuilder.data_loader as data_loader\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "from databuilder.data_generator import multi_input_data_organizer\n",
    "import databuilder.data_loader as data_loader\n",
    "from trainer.trainer import Trainer\n",
    "from model.build_model import TorchModel\n",
    "from utils import utils\n",
    "# import databuilder.nino_indices as nino_indices # CAUSES CELL TO HANG\n",
    "\n",
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"xarray version = {xr.__version__}\")\n",
    "print(f\"pytorch version = {torch.__version__}\")\n",
    "\n",
    "# https://github.com/victoresque/pytorch-template/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = utils.get_config(\"exp002\")\n",
    "seed = config[\"seed_list\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process + Pickle Inputs and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening MJO PCs\n",
      "Opening Nino34 Data\n",
      "/pscratch/sd/p/plutzner/E3SM/bigdata/E3SMv2data/member0101/member0101.Nino34.daily.int.nc\n",
      "Opening exp001 to extract target data for TRAINING\n",
      "Opening exp001 to extract target data for VALIDATION\n",
      "Opening exp001 to extract target data for TESTING\n",
      "Combining Input and target data\n",
      "(60225, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "s_dict_train, s_dict_val, s_dict_test = multi_input_data_organizer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan],\n",
       "       [ 0.73661584, -0.37304136,         nan],\n",
       "       [ 0.97043544,  0.09676895,         nan],\n",
       "       [ 1.14964592,  0.14846081,         nan],\n",
       "       [ 0.97928298,  0.19785374,         nan]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_dict_train[\"x\"][:124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_dict_savename1 = '/pscratch/sd/p/plutzner/E3SM/bigdata/presaved/exp002_train.pkl'\n",
    "with gzip.open(s_dict_savename1, \"wb\") as fp:\n",
    "    pickle.dump(s_dict_train, fp)\n",
    "\n",
    "s_dict_savename2 = '/pscratch/sd/p/plutzner/E3SM/bigdata/presaved/exp002_val.pkl'\n",
    "with gzip.open(s_dict_savename2, \"wb\") as fp:\n",
    "    pickle.dump(s_dict_val, fp)\n",
    "\n",
    "s_dict_savename3 = '/pscratch/sd/p/plutzner/E3SM/bigdata/presaved/exp002_test.pkl'\n",
    "with gzip.open(s_dict_savename3, \"wb\") as fp:\n",
    "    pickle.dump(s_dict_test, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve Data: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Setup the Data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainset \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mCustomData(\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_loader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp002_train.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m valset \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mCustomData(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_loader\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp002_val.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m      6\u001b[0m     trainset,\n\u001b[1;32m      7\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_loader\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data_loader'"
     ]
    }
   ],
   "source": [
    "# Setup the Data\n",
    "trainset = data_loader.CustomData(config[\"data_loader\"][\"data_dir\"] + \"exp002_train.pkl\")\n",
    "valset = data_loader.CustomData(config[\"data_loader\"][\"data_dir\"] + \"exp002_val.pkl\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=config[\"data_loader\"][\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=config[\"data_loader\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Model\n",
    "model = TorchModel(\n",
    "    config=config[\"arch\"],\n",
    "    target_mean=trainset.target.mean(axis=0),\n",
    "    target_std=trainset.target.std(axis=0),\n",
    ")\n",
    "model.freeze_layers(freeze_id=\"tau\")\n",
    "optimizer = getattr(torch.optim, config[\"optimizer\"][\"type\"])(\n",
    "    model.parameters(), **config[\"optimizer\"][\"args\"]\n",
    ")\n",
    "criterion = getattr(module_loss, config[\"criterion\"])()\n",
    "metric_funcs = [getattr(module_metric, met) for met in config[\"metrics\"]]\n",
    "\n",
    "# Build the trainer\n",
    "device = utils.prepare_device(config[\"device\"])\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    criterion,\n",
    "    metric_funcs,\n",
    "    optimizer,\n",
    "    max_epochs=config[\"trainer\"][\"max_epochs\"],\n",
    "    data_loader=train_loader,\n",
    "    validation_data_loader=val_loader,\n",
    "    device=device,\n",
    "    config=config,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-torch",
   "language": "python",
   "name": "env-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
